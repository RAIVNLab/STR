# Architecture
arch: LeNet5

# ===== Dataset ===== #
data: /usr/data
set: MultiMNIST
name: baseline
num_train_examples: 5000000
num_val_examples: 50000
num_concat: 5
num_classes: 100000


# ===== Learning Rate Policy ======== #
optimizer: sgd
lr: 0.1
lr_policy: cosine_lr
warmup_length: 5

# ===== Network training config ===== #
epochs: 100
weight_decay: 0.0001
momentum: 0.9
batch_size: 256


# ===== Sparsity =========== #
conv_type: DenseConv
bn_type: LearnedBatchNorm
init: kaiming_normal
mode: fan_in
nonlinearity: relu

# ===== Hardware setup ===== #
workers: 12
